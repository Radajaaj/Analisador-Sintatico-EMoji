# Analisador L√©xico E-moji
# Alunos: Fernando Seiji Onoda Inomata, Lucas Batista Deinzer Duarte, Vitor Mayorca Camargo

import sys
import os


# Isso ai vai mapear cada lexema/caractere/emoji para um tipo de token
#   Se fosse no C, isso seria um enum
TOKEN_MAP = {
    'üî¢': 'INT',              # Int
    'üî§': 'STRING_TYPE',      # string
    'ü§•': 'BOOL',             # booleano
    'üëç': 'TRUE',             # true
    'üëé': 'FALSE',            # false
    '‚ûï': 'OP_SOMA',          # +
    '‚ûñ': 'OP_SUB',           # -
    '‚úñÔ∏è': 'OP_MULT',          # *
    '‚ûó': 'OP_DIV',           # /
    'üêì': 'OP_MAIOR',         # >
    'üê£': 'OP_MENOR',         # <
    'ü•ö': 'OP_IGUAL_COMP',    # == (aritmetico)
    'ü§è': 'OP_AND',           # &&
    '‚úåÔ∏è': 'OP_OR',            # ||
    'ü§ù': 'OP_IGUAL_LOGICO',  # == (logico)
    'üëÇ': 'COMANDO_ENTRADA',  # scanf
    'üëÑ': 'COMANDO_SAIDA',    # printf
    'ü§®': 'IF',               # if
    'ü§î': 'ELSEIF',           # elif
    'üññ': 'ELSE',             # else
    'üòë': 'WHILE',            # while
    'üòÆ': 'FOR',              # for
    'ü§ú': 'ABRIR_BLOCO',      # {
    'ü§õ': 'FECHAR_BLOCO',     # }
    'üéÅ': 'ATRIBUICAO',       # Atribuicao (pra nao ter ambiguidade com o ü•ö)
    '(': 'ABRIR_PARENTESES',   # (
    ')': 'FECHAR_PARENTESES',  # )
    ';': 'PONTO_VIRGULA',      # ;
}


def analisar(codigo_fonte):
    """
    Fun√ß√£o que faz a an√°lise l√©xica do c√≥digo
    Entrada: string contendo um c√≥digo em e-moji
    Sa√≠da: tupla contendo (lista_de_tokens, status_sucesso).
    """
    tokens = []             # Lista pra guardar os tokens
    linha = 1               # Contador de linha para encontrar a posi√ß√£o do erro
    coluna = 1              # Contador de coluna, mesma coisa
    i = 0                   # Index que caminha pela string do codigo_fonte
    sucesso = True          # Flag, False indica erro
    
    # Loop principal, l√™ o c√≥digo caractere por caractere
    while i < len(codigo_fonte):
        char = codigo_fonte[i]

        # Pula espa√ßos brancos, quebra de linhas, tab, pois estes n√£o s√£o tokens
        if char.isspace():
            if char == '\n':    # Se for quebra de linha, incrementa a linha e reinicia a coluna
                linha += 1      
                coluna = 1      
            else:               # Se for espa√ßo ou tab, so incrementa a coluna 
                coluna += 1     
            i += 1              #pr√≥ximo caractere
            continue            #Volta pro come√ßo do while

        # PULA COMENT√ÅRIOS
        # Tudo que estiver entre ü§´ e üëÄ vai ser ignorado
        if char == 'ü§´':
            inicio_comentario_col = coluna
            i += 1              # Pula o emoji de in√≠cio de coment√°rio
            coluna += 1
            pos_inicial_comentario = i
            # dai l√™ at√© achar o emoji de fim de coment√°rio
            while i < len(codigo_fonte) and codigo_fonte[i] != 'üëÄ':
                i += 1
            
            # Chama um erro caso n√£o exista o emoji de fim de coment√°rio
            if i == len(codigo_fonte):
                print(f"Erro L√©xico: Coment√°rio iniciado na linha {linha} coluna {inicio_comentario_col} n√£o foi fechado.", file=sys.stderr)
                sucesso = False
                break 
            
            # Se achou o emoji, atualiza os contadores de linha/coluna
            # (para saber onde o c√≥digo continua depois do coment√°rio)
            comentario_conteudo = codigo_fonte[pos_inicial_comentario:i]
            novas_linhas = comentario_conteudo.count('\n')
            if novas_linhas > 0:
                linha += novas_linhas
                coluna = len(comentario_conteudo.split('\n')[-1]) + 1
            else:
                coluna += len(comentario_conteudo)
            
            i += 1 # Pula o 'üëÄ'
            coluna += 1
            continue # Volta pro come√ßo do while

        # Tokens com so um simbolo (operadores, pontua√ß√£o)
        # Verifica se o caractere atual pertence ao mapa de tokens
        if char in TOKEN_MAP:
            # Se sim, coloca o token na lista
            tokens.append((TOKEN_MAP[char], char, linha, coluna))
            i += 1          # vai pro pr√≥ximo caractere
            coluna += 1
            continue        # volta pro come√ßo do while
        
        # Identificadpres (vari√°veis)
        # ID come√ßa com uma letra
        if char.isalpha():
            lexema = char   # Armazena o primeiro caractere
            coluna_inicio = coluna
            i += 1
            coluna += 1
            while i < len(codigo_fonte) and (codigo_fonte[i].isalnum() or codigo_fonte[i] == '_'):  # De acprdo com a especifica√ßao do documento
                lexema += codigo_fonte[i]
                i += 1
                coluna += 1
            # Quando o loop acabar, temos o nome completo do id
            tokens.append(('ID', lexema, linha, coluna_inicio))
            continue

        # Numeros Inteiros
        # Numero come√ßa com um digit
        if char.isdigit():
            lexema = char   # Guarda o primeiro d√≠gito
            coluna_inicio = coluna
            i += 1
            coluna += 1
            # Continua lendo enquanto for d√≠gito
            while i < len(codigo_fonte) and codigo_fonte[i].isdigit():
                lexema += codigo_fonte[i]
                i += 1
                coluna += 1
            # Converte o resultado para int
            tokens.append(('NUMERO_INT', int(lexema), linha, coluna_inicio))
            continue
            
        # Strings
        # String come√ßa com aspas duplas "
        if char == '"':
            lexema = ''
            coluna_inicio = coluna
            i += 1      # Pula a aspa inicial
            coluna += 1
            # L√™ os caracteres, at√© a ultima aspa dupla
            while i < len(codigo_fonte) and codigo_fonte[i] != '"':
                # String nao deve ter quebra de linha (peguei o regex disso dos slides)
                if codigo_fonte[i] == '\n':
                    print(f"Erro L√©xico: String n√£o pode conter quebra de linha (erro na linha {linha}).", file=sys.stderr)
                    lexema = None
                    sucesso = False
                    break
                lexema += codigo_fonte[i]
                i += 1
                coluna += 1

            if not sucesso: break
            
            # Erro chamado no caso de n√£o encontrar a " que fecha a string
            if i == len(codigo_fonte):
                print(f"Erro L√©xico: String iniciada na linha {linha} coluna {coluna_inicio} n√£o foi fechada.", file=sys.stderr)
                sucesso = False
                break

            i += 1      # Pula a aspa final
            coluna += 1
            tokens.append(('STRING_LITERAL', lexema, linha, coluna_inicio))
            continue

        # O caractere n√£o se encaixa em nenhuma das regras acima. Erro
        print(f"Erro L√©xico: Caractere inesperado '{char}' na linha {linha}, coluna {coluna}.", file=sys.stderr)
        sucesso = False
        i += 1
        coluna += 1

    return tokens, sucesso

# --- Execu√ß√£o do Analisador ---
if __name__ == "__main__":                          #   O nome do arquivo a ser analisado vai ser inserido na chamada do programa
    if len(sys.argv) != 2:                          #   Que nem em compiladores normais
        print("Uso correto: python analisador.py <nome_do_arquivo.emoji>")
        sys.exit(1)
        
    nome_arquivo_entrada = sys.argv[1]              # Pega o primeiro argumento da chamada do programa
    
    if not nome_arquivo_entrada.endswith(".emoji"): # Valida extens√£o
        print("Erro: O arquivo de entrada deve ter a extens√£o .emoji")
        sys.exit(1)

    try:
        # Tenta abrir e ler o arquivo inserido
        # O 'with' garante que o arquivo √© fechado mesmo se der erro
        # O encoding tem que ser 'utf-8' para ler os emojis
        with open(nome_arquivo_entrada, 'r', encoding='utf-8') as f:
            codigo = f.read()
            
        # Chamamos a fun√ß√£o de analisar a string do codigo
        lista_de_tokens, analise_ok = analisar(codigo)
        
        # Gera o arquivo de sa√≠da apenas se a analise deu certo
        if analise_ok and lista_de_tokens:
            # Cria o nome do arquivo de saida, trocando a extens√£o
            base_name = os.path.splitext(nome_arquivo_entrada)[0]   # Pega o nome do arquivo sem a extens√£o
            nome_arquivo_saida = base_name + ".emojilex"
            
            # Abre o arquivo de sa√≠da em modo de escrita ('w')
            with open(nome_arquivo_saida, 'w', encoding='utf-8') as f_out:
                f_out.write("-" * 50 + "\n")
                f_out.write("AN√ÅLISE L√âXICA CONCLU√çDA - TOKENS GERADOS\n")
                f_out.write("-" * 50 + "\n")
                # Itera sobre a lista de tokens e escreve cada um no arquivo
                for token in lista_de_tokens:
                    tipo, valor, linha, col = token
                    f_out.write(f"[{tipo}, '{valor}', L:{linha}, C:{col}]\n")
                f_out.write("-" * 50 + "\n")
            
            print(f"An√°lise conclu√≠da com sucesso. Tokens salvos em '{nome_arquivo_saida}'")
        elif not analise_ok:
            print("\nAn√°lise l√©xica falhou devido a erros. Nenhum arquivo de sa√≠da foi gerado.", file=sys.stderr)
        else:
            print("Nenhum token foi encontrado no arquivo.")

    # Se o arquivo n√£o for encontrado, erro
    except FileNotFoundError:
        print(f"Erro: Arquivo '{nome_arquivo_entrada}' n√£o encontrado.")
        sys.exit(1)